{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1         2         3         4         5         6    \\\n",
      "0     -0.076968 -0.004365  0.019731  0.009190 -0.050608  0.008721  0.038924   \n",
      "1     -0.049463 -0.020196 -0.008273  0.017458 -0.000435  0.024264  0.063787   \n",
      "2      0.010414 -0.018651  0.003080 -0.005116  0.032243  0.015521  0.030721   \n",
      "3     -0.055945 -0.047393 -0.033989 -0.006274 -0.022510 -0.012531 -0.000599   \n",
      "4     -0.073024  0.032800  0.062011 -0.028722  0.091838 -0.014950 -0.089704   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "24995  0.003648  0.093710  0.041927 -0.005563 -0.023833 -0.002938  0.009442   \n",
      "24996 -0.018505  0.007941  0.037602 -0.021426 -0.033456  0.011947  0.023734   \n",
      "24997  0.013416  0.001527  0.011863 -0.006423 -0.032362 -0.018805  0.007866   \n",
      "24998 -0.037110  0.023442  0.057732  0.020060  0.011861  0.004493  0.024458   \n",
      "24999 -0.010869 -0.014892 -0.015014  0.014490  0.034367 -0.013109  0.014245   \n",
      "\n",
      "            7         8         9    ...       240       241       242  \\\n",
      "0     -0.015857 -0.051825 -0.005419  ...  0.002982 -0.019309  0.030641   \n",
      "1      0.010397 -0.024440 -0.007147  ... -0.010515 -0.008003 -0.009727   \n",
      "2      0.011866 -0.006397 -0.019127  ...  0.012692 -0.008252  0.000372   \n",
      "3     -0.009893  0.017959  0.045153  ... -0.019176  0.006587  0.037442   \n",
      "4     -0.077591 -0.001766  0.069365  ...  0.009451  0.001020  0.007571   \n",
      "...         ...       ...       ...  ...       ...       ...       ...   \n",
      "24995 -0.011791 -0.001766 -0.036987  ... -0.003139  0.023806 -0.000895   \n",
      "24996  0.002749 -0.011566 -0.033674  ...  0.020231 -0.014457 -0.010380   \n",
      "24997 -0.037939 -0.016086 -0.006874  ...  0.004579  0.001973 -0.020852   \n",
      "24998  0.024754 -0.010720 -0.020852  ...  0.007689  0.012657  0.014457   \n",
      "24999 -0.007571 -0.041704  0.020714  ...  0.011166  0.010707  0.008021   \n",
      "\n",
      "            243       244       245       246       247       248       249  \n",
      "0     -0.012735 -0.006079  0.016300 -0.014379 -0.000046  0.014919 -0.017264  \n",
      "1      0.005301  0.003921  0.004127 -0.016411  0.006382 -0.010542 -0.016767  \n",
      "2      0.013031  0.015741  0.006966 -0.008405  0.001511  0.011117  0.000748  \n",
      "3     -0.014762  0.028792  0.009827  0.005106  0.012412 -0.014926  0.009244  \n",
      "4     -0.003429  0.007537 -0.012678  0.019607 -0.002220  0.035392 -0.028087  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "24995  0.001943 -0.023405  0.014984  0.001964 -0.005031 -0.001456 -0.013808  \n",
      "24996 -0.010425  0.007647 -0.001855  0.002934 -0.006998  0.011060 -0.010220  \n",
      "24997  0.010958 -0.012875 -0.002922  0.003678  0.011722  0.006484  0.011758  \n",
      "24998 -0.013378  0.005792 -0.003162  0.003624  0.005955  0.007358  0.000905  \n",
      "24999 -0.024284 -0.006669  0.020214 -0.025565  0.017294 -0.000230 -0.000571  \n",
      "\n",
      "[25000 rows x 250 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "trainingdata = np.load(\"train.mat\")\n",
    "traindat = pd.DataFrame(data=trainingdata)\n",
    "print(traindat)\n",
    "\n",
    "label = []\n",
    "\n",
    "for line in open(\"train.labels\"):\n",
    "    label.append(int(line))\n",
    "\n",
    "labels = pd.DataFrame(data=label)\n",
    "#print(labels[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "\tdef __init__(self, rate = 0.01, number_of_iterations = 100):\n",
    "\t\tself.rate = rate\n",
    "\t\tself.number_of_iterations = number_of_iterations\n",
    "\n",
    "\tdef fit(self, X, y):\n",
    "\t\t\"\"\" Fit training data\n",
    "\t\t\n",
    "\t\tParameters:\n",
    "\t\t------------\n",
    "\t\tX : array-like, shape = [number_of_samples, number_of_features]\n",
    "\t\t\tTraining vectors.\n",
    "\t\ty : array-like, shape = [number_of_samples]\n",
    "\t\t\tTarget values.\n",
    "\n",
    "\t\tReturns\n",
    "\t\t------------\n",
    "\t\tself : object\n",
    "\n",
    "\t\t\"\"\"\n",
    "\t\t\n",
    "\t\tself.weight_matrix = np.zeros(1 + X.shape[1])\n",
    "\t\tself.errors_list = []\n",
    "\n",
    "\t\tfor _ in range(self.number_of_iterations):\n",
    "\t\t\terrors = 0\n",
    "\t\t\tfor xi, target in zip(X, y):\n",
    "\t\t\t\tupdate = self.rate * (target - self.predict(xi))\n",
    "\t\t\t\tself.weight_matrix[1:] += update * xi\n",
    "\t\t\t\tself.weight_matrix[0] += update\n",
    "\t\t\t\terrors += int(update != 0.0)\n",
    "\t\t\tself.errors_list.append(errors)\n",
    "\t\treturn self\n",
    "\n",
    "\tdef dot_product(self, X):\n",
    "\t\t\"\"\" Calculate the dot product \"\"\"\n",
    "\t\treturn (np.dot(X, self.weight_matrix[1:]) + self.weight_matrix[0])\n",
    "\n",
    "\tdef predict(self, X):\n",
    "\t\t\"\"\" Predicting the label for the input data \"\"\"\n",
    "\t\treturn np.where(self.dot_product(X) >= 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 250)\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "per = Perceptron()\n",
    "\n",
    "per.fit(trainingdata, labels)\n",
    "\n",
    "#print(per.weight_matrix)\n",
    "\n",
    "testingdata = np.load(\"test.mat\")\n",
    "testdat = pd.DataFrame(data=testingdata)\n",
    "print(testdat.shape)\n",
    "\n",
    "results = []\n",
    "\n",
    "for index, sample in testdat.iterrows():\n",
    "    prediction = per.predict(sample)\n",
    "    if prediction != 1:\n",
    "        print(\"Testing Sample {} predicts: {}\".format(index, prediction))\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\n",
      "Error:0.498400000444744\n",
      "Step 100\n",
      "Error:0.4984000007389507\n",
      "Step 200\n",
      "Error:0.4984000021683491\n",
      "Step 300\n",
      "Error:0.5016\n",
      "Step 400\n",
      "Error:0.5016\n",
      "Step 500\n",
      "Error:0.5016\n",
      "(2500,)\n",
      "[1. 1. 1. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "trainingdata = np.load(\"train.mat\")\n",
    "traindat = trainingdata[0:2500]#pd.DataFrame(data=trainingdata[0:1000])\n",
    "\n",
    "label = []\n",
    "\n",
    "for line in open(\"train.labels\"):\n",
    "    lbl = int(line)\n",
    "    if lbl != 1:\n",
    "        lbl = 0\n",
    "    label.append(lbl)\n",
    "\n",
    "labels = label[0:2500]#pd.DataFrame(data=label[0:1000])\n",
    "\n",
    "def nonlin(x,deriv=False):\n",
    "    if(deriv==True):\n",
    "        return x*(1-x)\n",
    "    #return sp.special.expit(x)\n",
    "    return 1/(1+np.exp(-x))\n",
    "    \n",
    "def train_model(X, y):\n",
    "\n",
    "    np.random.seed(1)\n",
    "\n",
    "    # randomly initialize our weights with mean 0\n",
    "    syn0 = 2*np.random.random(np.shape(X)) - 1\n",
    "    syn1 = 2*np.random.random(np.shape(y)) - 1\n",
    "    \n",
    "    l2 = []\n",
    "    \n",
    "    for j in range(600):\n",
    "\n",
    "        if (j % 100) == 0:\n",
    "            print(\"Step {}\".format(j))\n",
    "        # Feed forward through layers 0, 1, and 2\n",
    "        l0 = X\n",
    "        l1 = nonlin(np.dot(l0,syn0.T))\n",
    "        #print(l1.shape)\n",
    "        #print(l0.T.shape)\n",
    "        #print(syn0.shape)\n",
    "        l2 = nonlin(np.dot(l1,syn1))\n",
    "\n",
    "        # how much did we miss the target value?\n",
    "        l2_error = y - l2\n",
    "\n",
    "        if (j% 100) == 0:\n",
    "            print(\"Error:\" + str(np.mean(np.abs(l2_error))))\n",
    "\n",
    "        # in what direction is the target value?\n",
    "        # were we really sure? if so, don't change too much.\n",
    "        l2_delta = l2_error*nonlin(l2,deriv=True)\n",
    "\n",
    "        # how much did each l1 value contribute to the l2 error (according to the weights)?\n",
    "        l1_error = l2_delta.dot(syn1.T)\n",
    "\n",
    "        # in what direction is the target l1?\n",
    "        # were we really sure? if so, don't change too much.\n",
    "        l1_delta = l1_error * nonlin(l1,deriv=True)\n",
    "\n",
    "        syn1 += l1.T.dot(l2_delta)\n",
    "        syn0 += (l0.T.dot(l1_delta.T)).T\n",
    "    \n",
    "    return l2\n",
    "        \n",
    "theta = train_model(traindat, labels)\n",
    "print(theta.shape)\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
