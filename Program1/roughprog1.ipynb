{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Training.\n",
      "Starting to Train Neural Network for 3000 iterations\n",
      "\n",
      "Iteration 0 of 3000\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "Iteration 250 of 3000\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "Iteration 500 of 3000\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "Iteration 750 of 3000\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "Iteration 1000 of 3000\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "Iteration 1250 of 3000\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "Iteration 1500 of 3000\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "Iteration 1750 of 3000\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "Iteration 2000 of 3000\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "Iteration 2250 of 3000\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "Iteration 2500 of 3000\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "Iteration 2750 of 3000\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "Iteration 2999 of 3000\n",
      "XTraining Complete.\n",
      "Beginning Predictions.\n",
      "Predictions Complete.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-73849838901c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"results.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresultsfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mresultsfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"+1\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not iterable"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.random as r\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainingdata = np.load(\"train.mat\")\n",
    "X = trainingdata#[0:1000]\n",
    "\n",
    "label = []\n",
    "for line in open(\"train.labels\"):\n",
    "    lbl = int(line)\n",
    "    #if lbl != 1:\n",
    "    #    lbl = 0\n",
    "    label.append(lbl)\n",
    "y = label#[0:1000]\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Set up the neural network\n",
    "#nn_structure = [X_train.shape[1], 50, 1]\n",
    "#print(nn_structure)\n",
    "\n",
    "def f(x):\n",
    "    #return 1 / (1 + np.exp(-x))\n",
    "    return np.tanh(x)\n",
    "\n",
    "def f_deriv(x):\n",
    "    #return f(x) * (1 - f(x))\n",
    "    return 1.0 - np.tanh(x)**2\n",
    "\n",
    "# Initialize parameters to random values\n",
    "def setup_and_init_weights(nn_structure):\n",
    "    W = {}\n",
    "    b = {}\n",
    "    for l in range(1, len(nn_structure)):\n",
    "        W[l] = r.random_sample((nn_structure[l], nn_structure[l-1]))\n",
    "        b[l] = r.random_sample((nn_structure[l], 1))\n",
    "    return W, b\n",
    "\n",
    "def init_tri_values(nn_structure):\n",
    "    tri_W = {}\n",
    "    tri_b = {}\n",
    "    for l in range(1, len(nn_structure)):\n",
    "        tri_W[l] = np.zeros((nn_structure[l], nn_structure[l-1]))\n",
    "        tri_b[l] = np.zeros((nn_structure[l], 1))\n",
    "    return tri_W, tri_b\n",
    "\n",
    "def feed_forward(x, W, b):\n",
    "    h = {1: x}\n",
    "    z = {}\n",
    "    for l in range(1, len(W) + 1):\n",
    "        # if it is the first layer, then the input into the weights is x, otherwise, \n",
    "        # it is the output from the last layer\n",
    "        if l == 1:\n",
    "            node_in = x\n",
    "        else:\n",
    "            node_in = h[l]\n",
    "        #node_in_p = node_in.to_numpy().reshape(node_in.shape[0], 1)\n",
    "        z[l+1] = W[l].dot(node_in) + b[l] # z^(l+1) = W^(l)*h^(l) + b^(l)  \n",
    "        h[l+1] = f(z[l+1]) # h^(l) = f(z^(l)) \n",
    "    return h, z\n",
    "\n",
    "def calculate_out_layer_delta(y, h_out, z_out):\n",
    "    # delta^(nl) = -(y_i - h_i^(nl)) * f'(z_i^(nl))\n",
    "    #return -(y - h_out) * f_deriv(z_out)\n",
    "    #y_p = y.to_numpy()\n",
    "    #y_p = y_p.reshape(y.shape[0], 1)\n",
    "    #return np.multiply(-(y_p - h_out), f_deriv(z_out))\n",
    "    return np.multiply(-(y - h_out), f_deriv(z_out))\n",
    "\n",
    "def calculate_hidden_delta(delta_plus_1, w_l, z_l):\n",
    "    # delta^(l) = (transpose(W^(l)) * delta^(l+1)) * f'(z^(l))\n",
    "    #return np.dot(np.transpose(w_l), delta_plus_1) * f_deriv(z_l)\n",
    "    return np.multiply(np.dot(w_l.T, delta_plus_1), f_deriv(z_l))\n",
    "\n",
    "def train_nn(nn_structure, X, y, iter_num=3000, alpha=0.25):\n",
    "    W, b = setup_and_init_weights(nn_structure)\n",
    "    cnt = 0\n",
    "    m = len(y)\n",
    "    avg_cost_func = []\n",
    "    print('Starting to Train Neural Network for {} iterations'.format(iter_num))\n",
    "    while cnt < iter_num:\n",
    "        if cnt%250 == 0 or cnt==(iter_num-1):\n",
    "            print('\\nIteration {} of {}'.format(cnt, iter_num))\n",
    "        tri_W, tri_b = init_tri_values(nn_structure)\n",
    "        avg_cost = 0\n",
    "        for i in range(len(y)):\n",
    "            delta = {}\n",
    "            # perform the feed forward pass and return the stored h and z values, to be used in the\n",
    "            # gradient descent step\n",
    "            #print(\"sample: {}\".format(i))\n",
    "            h, z = feed_forward(X[i].reshape(X[i].shape[0],1), W, b)\n",
    "            # loop from nl-1 to 1 backpropagating the errors\n",
    "            for l in range(len(nn_structure), 0, -1):\n",
    "                if l == len(nn_structure):\n",
    "                    delta[l] = calculate_out_layer_delta(y[i], h[l], z[l])#y.T[i], h[l], z[l])\n",
    "                    avg_cost += np.linalg.norm((y[i] - np.sum(h[l])))#y.T[i] - np.sum(h[l])))\n",
    "                else:\n",
    "                    if l > 1:\n",
    "                        delta[l] = calculate_hidden_delta(delta[l+1], W[l], z[l])\n",
    "                    # triW^(l) = triW^(l) + delta^(l+1) * transpose(h^(l))\n",
    "                    #tri_W[l] += np.dot(delta[l+1][:,np.newaxis], np.transpose(h[l][:,np.newaxis])) \n",
    "                    tri_W[l] += np.dot(delta[l+1], h[l].T)\n",
    "                    # trib^(l) = trib^(l) + delta^(l+1)\n",
    "                    tri_b[l] += np.sum(delta[l+1])\n",
    "        # perform the gradient descent step for the weights in each layer\n",
    "        for l in range(len(nn_structure) - 1, 0, -1):\n",
    "            W[l] += -alpha * (1.0/m * tri_W[l])\n",
    "            b[l] += -alpha * (1.0/m * tri_b[l])\n",
    "        # complete the average cost calculation\n",
    "        avg_cost = 1.0/m * avg_cost\n",
    "        avg_cost_func.append(avg_cost)\n",
    "        cnt += 1\n",
    "        print(\"X\",end=\"\")\n",
    "    return W, b, avg_cost_func\n",
    "\n",
    "# Train model and plot cost function\n",
    "#W, b, avg_cost_func = train_nn(nn_structure, X_train, y_train)\n",
    "#plt.plot(avg_cost_func)\n",
    "#plt.ylabel('Average J')\n",
    "#plt.xlabel('Iteration number')\n",
    "#plt.show()\n",
    "\n",
    "# Assess model performance\n",
    "def predict_y(W, b, X, n_layers):\n",
    "    m = X.shape[0]\n",
    "    y = np.zeros((m,1))\n",
    "    for i in range(m):\n",
    "        #h, z = feed_forward(X[i, :], W, b)\n",
    "        h, z = feed_forward(X[i].reshape(X[i].shape[0],1), W, b)\n",
    "        #y[i] = np.argmax(h[n_layers])\n",
    "        #print(h[n_layers])\n",
    "        y[i] = 1 if h[n_layers] >= 0 else -1\n",
    "        #print(y[i] == y_test[i])\n",
    "    return y\n",
    "\n",
    "print(\"Begin Training.\")\n",
    "nn_structure = [X.shape[1], 50, 1]\n",
    "W, b, avg_cost_func = train_nn(nn_structure, X, y)\n",
    "print(\"Training Complete.\")\n",
    "\n",
    "X_test = np.load(\"test.mat\")\n",
    "\n",
    "print(\"Beginning Predictions.\")\n",
    "y_pred = predict_y(W, b, X_test, len(nn_structure))\n",
    "#print(y_pred)\n",
    "print (\"Predictions Complete.\")\n",
    "#print(accuracy_score(y_test, y_pred)*100)\n",
    "\n",
    "with open(\"results.txt\", \"w\") as resultsfile:\n",
    "    for y in y_pred:\n",
    "        if y == 1:\n",
    "            resultsfile.write(\"+1\\n\")\n",
    "            #print(\"+1\", file=resultsfile)\n",
    "        else:\n",
    "            resultsfile.write(\"-1\\n\")\n",
    "            #print(\"-1\", file=resultsfile)\n",
    "\n",
    "print(\"Predictions stored in results.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions stored in results.txt\n"
     ]
    }
   ],
   "source": [
    "with open(\"results.txt\", \"w\") as resultsfile:\n",
    "    for y in y_pred:\n",
    "        if y == 1:\n",
    "            resultsfile.write(\"+1\\n\")\n",
    "            #print(\"+1\", file=resultsfile)\n",
    "        else:\n",
    "            resultsfile.write(\"-1\\n\")\n",
    "            #print(\"-1\", file=resultsfile)\n",
    "\n",
    "print(\"Predictions stored in results.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hubpy3.7-tf2.1",
   "language": "python",
   "name": "hubpy3.7-tf2.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
